{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac204ae7-b928-44cf-9e2c-f9856419ef65",
   "metadata": {},
   "source": [
    "# üíæ Saving and üöÄ Deploying Machine Learning Models\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Why Save Models?\n",
    "\n",
    "Once your model is trained and tuned, saving it allows:\n",
    "- Reuse without retraining\n",
    "- Sharing with others\n",
    "- Deployment in production\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Common Formats for Saving Models\n",
    "\n",
    "| Format      | Library         | Use Case                            |\n",
    "|-------------|------------------|-------------------------------------|\n",
    "| `.pkl`      | `joblib`, `pickle` | General Python object storage       |\n",
    "| `.joblib`   | `joblib`         | Efficient for large NumPy arrays    |\n",
    "| `.h5`, `.hdf5` | `Keras`, `TensorFlow` | Deep learning models         |\n",
    "| `.onnx`     | `ONNX`           | Interoperability between frameworks |\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Saving Models in Python\n",
    "\n",
    "### Using `joblib` (Recommended for sklearn models)\n",
    "\n",
    "```python\n",
    "from joblib import dump, load\n",
    "\n",
    "# Save model\n",
    "dump(model, 'model.joblib')\n",
    "\n",
    "# Load model\n",
    "model = load('model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ea1b5-2a62-40b1-b547-33db366e0544",
   "metadata": {},
   "source": [
    "## Using pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae564a-e608-45c0-92b1-f74baa00e82c",
   "metadata": {},
   "source": [
    "```python\n",
    "import pickle\n",
    "\n",
    "# Save\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Load\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394876c-330a-49cc-9f9d-57375426b6a1",
   "metadata": {},
   "source": [
    "## üöÄ Model Deployment\n",
    "Deployment allows users to access the model's predictions via applications, websites, or APIs.\n",
    "\n",
    "üõ†Ô∏è Common Deployment Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fcbb60-e7b2-4964-b405-f4c944911dd5",
   "metadata": {},
   "source": [
    "| Method          | Description                             |\n",
    "| --------------- | --------------------------------------- |\n",
    "| Flask / FastAPI | Lightweight REST APIs for ML services   |\n",
    "| Streamlit       | Python apps for data science dashboards |\n",
    "| Docker          | Containerize your model + app           |\n",
    "| Cloud Services  | AWS, Azure, GCP, Heroku, etc.           |\n",
    "| ONNX            | Deploy across platforms & hardware      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171bdea-e9ec-4a65-a881-45d2a31b5d30",
   "metadata": {},
   "source": [
    "## üåê Example: API Deployment with FastAPI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc432ffd-09a6-4d29-9ab7-95448fd66cae",
   "metadata": {},
   "source": [
    "```python\n",
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "model = joblib.load('model.joblib')\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Model is ready\"}\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "def predict(data: list):\n",
    "    prediction = model.predict([np.array(data)])\n",
    "    return {\"prediction\": prediction.tolist()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16245809-3bea-4eaa-914a-9d5e0788b200",
   "metadata": {},
   "source": [
    "## ‚úÖ Best Practices\n",
    "\n",
    "Keep preprocessing steps in the same pipeline\n",
    "\n",
    "Validate the model before saving\n",
    "\n",
    "Use version control for models\n",
    "\n",
    "Log metrics and configurations (e.g., using MLflow or DVC)\n",
    "\n",
    "Use REST APIs or cloud platforms for scalable deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51251a-d06a-49c7-a223-81b8dcd724b8",
   "metadata": {},
   "source": [
    "üí° Tip: Always save the entire pipeline (e.g., scaler + model) to avoid mismatches during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9b1a3-b99e-4d16-adff-5febe088c2d9",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "dump(pipeline, 'pipeline.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8fda36-be8f-414a-b933-816873986633",
   "metadata": {},
   "source": [
    "## üì¨ Conclusion\n",
    "Saving and deploying models is a critical part of the ML lifecycle. It ensures that your model is accessible, reusable, and production-ready. Choose the right tool and format based on your use case and deployment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1be81-03ef-4cd2-b886-aab41755e1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
