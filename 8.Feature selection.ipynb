{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ce17ac-fbd2-4d28-95cb-e954123e967f",
   "metadata": {},
   "source": [
    "# üìå Feature Selection in Machine Learning  \n",
    "\n",
    "Feature selection is the process of selecting the most **relevant features (variables)** from your dataset that contribute the most to predicting the target variable.  \n",
    "\n",
    "This step improves:  \n",
    "- ‚úÖ Model accuracy  \n",
    "- ‚úÖ Training speed  \n",
    "- ‚úÖ Model interpretability  \n",
    "- ‚úÖ Reduces overfitting  \n",
    "\n",
    "---\n",
    "\n",
    "## üîé Types of Feature Selection Methods  \n",
    "\n",
    "### 1Ô∏è‚É£ Filter Methods  \n",
    "These rely on statistical measures to evaluate the relationship between independent variables and the target.  \n",
    "\n",
    "- **Correlation Coefficient** (for numerical variables)  \n",
    "- **Chi-Square Test** (for categorical variables)  \n",
    "- **ANOVA Test**  \n",
    "\n",
    "üëâ These are fast but don‚Äôt consider model performance.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Wrapper Methods  \n",
    "These use a predictive model to evaluate the combination of features.  \n",
    "\n",
    "- **Recursive Feature Elimination (RFE)**: Iteratively removes least important features.  \n",
    "- More accurate but computationally expensive.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Embedded Methods  \n",
    "Feature selection occurs during model training.  \n",
    "\n",
    "- **Lasso (L1 Regularization)** shrinks less important features‚Äô coefficients to zero.  \n",
    "- **Tree-based models (RandomForest, XGBoost)** provide built-in feature importance.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ Dimensionality Reduction  \n",
    "Instead of selecting features, this **creates new features** by combining existing ones.  \n",
    "\n",
    "- **Principal Component Analysis (PCA)**  \n",
    "- **t-SNE, UMAP** (for visualization and high-dimensional data)  \n",
    "\n",
    "---\n",
    "\n",
    "## üßë‚Äçüíª Hands-on Code Examples  \n",
    "\n",
    "### Import Libraries & Dataset\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756e1d8-7be0-40c9-9eac-59fb84030b07",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42e9c0-fe36-47c4-b76c-e4beb052bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample dataset\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.Series(boston.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5247918-ca38-4f21-99fc-3513d18f3c96",
   "metadata": {},
   "source": [
    "### 1. Filter Method ‚Äì SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ded2c-1188-4d75-816c-dd8ba75091db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ANOVA F-test (f_regression)\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected Features (Filter Method):\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af416-1b34-4183-a496-1eb2a82eba38",
   "metadata": {},
   "source": [
    "### 2. Wrapper Method ‚Äì RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085f06f-7677-4186-943e-81f90197f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "selected_features_rfe = X.columns[fit.support_]\n",
    "print(\"Selected Features (Wrapper Method - RFE):\", selected_features_rfe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1f60f-c6f7-4327-8317-f2f08ae608d0",
   "metadata": {},
   "source": [
    "### 3. Embedded Method ‚Äì Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9efd7-45fc-4869-9880-8c9a57515e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "selected_features_lasso = X.columns[lasso.coef_ != 0]\n",
    "print(\"Selected Features (Embedded Method - Lasso):\", selected_features_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c47c5c-2279-445d-931b-be24e8cd9373",
   "metadata": {},
   "source": [
    "### 4. Embedded Method ‚Äì RandomForest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db02637-2f82-49f6-b069-a874bb730a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(importances.sort_values(ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef8d13-84b2-4e6f-b9ed-83c409c5c53b",
   "metadata": {},
   "source": [
    "### 5. Dimensionality Reduction ‚Äì PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac105c-2e48-4a15-aac5-d84fda1f8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"Explained Variance Ratio (Top 5 PCA components):\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d8228-bd2b-41e7-969d-e89e735c0f86",
   "metadata": {},
   "source": [
    "##  Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768edbf4-e851-4d5b-b7a1-58d6f3ba89c6",
   "metadata": {},
   "source": [
    "Feature selection reduces noise & redundancy in data.\n",
    "\n",
    "Use Filter methods for quick pre-selection.\n",
    "\n",
    "Apply Wrapper & Embedded methods for model-based refinement.\n",
    "\n",
    "Consider PCA/Dimensionality Reduction when dealing with very high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e8ded-f0c6-4de5-b13a-94b638753f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
