{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee39576-246c-429f-b900-ba4ee12811a1",
   "metadata": {},
   "source": [
    "# üß± Feature Engineering in Machine Learning\n",
    "\n",
    "## üß† What is Feature Engineering?\n",
    "\n",
    "**Feature Engineering** is the process of using domain knowledge and data understanding to **create, transform, or select** features that improve the performance of machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives of Feature Engineering\n",
    "\n",
    "- Enhance **model accuracy** by providing meaningful input\n",
    "- Reduce **noise and redundancy** in features\n",
    "- Enable **simpler models** by removing irrelevant data\n",
    "- Make models more **interpretable** and **generalizable**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Key Steps in Feature Engineering\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Feature Creation\n",
    "\n",
    "**Definition**: Creating new features by combining or transforming existing ones.\n",
    "\n",
    "#### üìå Examples:\n",
    "- Total cost = Quantity √ó Price\n",
    "- Age from Date of Birth\n",
    "- Text length = `len(text)`\n",
    "\n",
    "```python\n",
    "df['total_cost'] = df['quantity'] * df['unit_price']\n",
    "df['text_length'] = df['review'].apply(len)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3fe1d-e276-48f3-a0ab-86503e20aded",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Feature Transformation\n",
    "Definition: Converting features into forms suitable for modeling.\n",
    "\n",
    "### üî∏ a. Scaling (Normalization / Standardization)\n",
    "\n",
    "**Standardization: Mean = 0, SD = 1**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'salary']] = scaler.fit_transform(df[['age', 'salary']])\n",
    "```\n",
    "**Min-Max Scaling: Rescales data to [0, 1]**\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[['age', 'income']] = scaler.fit_transform(df[['age', 'income']])\n",
    "```\n",
    "### üî∏ b. Log Transform / Power Transform\n",
    "Useful for skewed data or heteroscedasticity\n",
    "```python\n",
    "import numpy as np\n",
    "df['log_income'] = np.log1p(df['income'])\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a469253-90ff-4b0d-b8f0-d74f75942610",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Encoding Categorical Features\n",
    "\n",
    "### üî∏ a. Label Encoding\n",
    "Assigns numerical values to each category (ordinal)\n",
    "\n",
    "``` PYTHON\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "```\n",
    "### üî∏ b. One-Hot Encoding\n",
    "Converts each category into separate binary columns (nominal)\n",
    "``` python\n",
    "pd.get_dummies(df, columns=['city'], drop_first=True)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5beeb5-18c9-48ee-83a4-f86bcd6f3f13",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Binning\n",
    "Definition: Convert continuous variables into categorical by dividing them into bins.\n",
    "\n",
    "```python\n",
    "\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 60, 100], labels=['Teen', 'Young Adult', 'Adult', 'Senior'])\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37453793-1ca8-4f48-849c-62728084c7de",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Date-Time Feature Extraction\n",
    "Extract useful components from date fields like year, month, day, hour, weekday.\n",
    "\n",
    "```python\n",
    "\n",
    "df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "df['month'] = df['purchase_date'].dt.month\n",
    "df['weekday'] = df['purchase_date'].dt.day_name()\n",
    "df['hour'] = df['purchase_date'].dt.hour\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753d836-0427-4ff4-941b-9c76b6d86b70",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Text Feature Extraction\n",
    "### üî∏ a. Word Count / Character Count\n",
    "``` python\n",
    "df['char_count'] = df['review'].apply(len)\n",
    "df['word_count'] = df['review'].apply(lambda x: len(str(x).split()))\n",
    "```\n",
    "### üî∏ b. TF-IDF Vectorization (for ML models)\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "X = tfidf.fit_transform(df['review'])\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84decb8-32a9-48ac-955e-f55cfd56ac0a",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Feature Selection\n",
    "Definition: Selecting the most relevant features for the model.\n",
    "\n",
    "Methods:\n",
    "- Correlation Matrix\n",
    "- Univariate Feature Selection (SelectKBest)\n",
    "- Recursive Feature Elimination (RFE)\n",
    "- Tree-based importance (e.g., RandomForestClassifier)\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09f2f1-b176-42ab-aa5a-c9270cc36202",
   "metadata": {},
   "source": [
    "| Technique          | Purpose                       | Example Tool                     |\n",
    "| ------------------ | ----------------------------- | -------------------------------- |\n",
    "| Feature Creation   | Add domain knowledge          | `df['total'] = A * B`            |\n",
    "| Scaling            | Normalize data                | `StandardScaler`, `MinMaxScaler` |\n",
    "| Encoding           | Convert categories to numbers | `LabelEncoder`, `get_dummies()`  |\n",
    "| Binning            | Discretize continuous data    | `pd.cut()`                       |\n",
    "| Text Processing    | Extract info from text        | `TfidfVectorizer()`              |\n",
    "| Date-Time Features | Add time-based columns        | `.dt.month`, `.dt.hour`          |\n",
    "| Feature Selection  | Remove irrelevant variables   | `SelectKBest`, `RFE`             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb1a22-4ff1-4432-912a-9c59717e4b71",
   "metadata": {},
   "source": [
    "## üßæ Final Notes\n",
    "- Feature Engineering is often more impactful than choosing the algorithm.\n",
    "- Good features simplify models, improve accuracy, and reduce overfitting.\n",
    "- Combine domain knowledge + statistical insight + EDA for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c1ee4-c055-4632-94d5-7e0cdca4de25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
